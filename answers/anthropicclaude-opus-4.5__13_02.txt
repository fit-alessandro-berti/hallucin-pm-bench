## Analysis Results

### 1. Frequency of "Manual_Fraud_Check"

**1 occurrence** (in case C05)

---

### 2. Percentages

| Metric | Calculation | Result |
|--------|-------------|--------|
| a) % of all events | 1 / 48 × 100 | **2.08%** |
| b) % of all cases | 1 / 12 × 100 | **8.33%** |

---

### 3. Why Low-Support Activities Mislead Analyses

With only **one instance**, Manual_Fraud_Check lacks statistical reliability. Any performance metric (e.g., duration, outcome correlation) derived from it reflects a **single observation**, not a pattern. Predictive models trained on this slice may either:
- **Ignore** the activity due to insufficient support, missing important edge cases, or
- **Overfit** to that one case's characteristics (C05 was approved quickly).

Generalizing from n=1 risks false conclusions about when manual checks occur, their impact on cycle time, or their correlation with approval/rejection outcomes.