1) **Occurrences of “Manual_Fraud_Check”**: **1** (only in case **C05**).

2) **Percentages including that activity** (rounded to two decimals):  
a) Of all **events**: \( \frac{1}{48} \times 100 = 2.08\% \) → **2.08%**  
b) Of all **unique cases (12)**: \( \frac{1}{12} \times 100 = 8.33\% \) → **8.33%**

3) **Why low support can mislead (≤100 words)**  
With only 1 occurrence (1 case), “Manual_Fraud_Check” is too rare to estimate reliable performance (e.g., its typical lead time or impact on approval/rejection). Any measured effect is dominated by a single instance (C05), so it may reflect an outlier rather than a stable pattern. Predictive models can overfit to this noise, mis-rank its importance, or fail to generalise—especially if the full process contains more (or different) manual checks than this small slice shows.