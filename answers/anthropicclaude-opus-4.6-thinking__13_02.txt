

## Answers

### 1. Occurrence count

**Manual\_Fraud\_Check** appears exactly **1 time** (in case **C05**).

---

### 2. Percentages

| Metric | Calculation | Result |
|---|---|---|
| **(a) Share of all events** | 1 / 48 | **2.08 %** |
| **(b) Share of unique cases** | 1 / 12 | **8.33 %** |

---

### 3. Why low-support activities can mislead (≤ 100 words)

With only a single observation, any statistic derived from **Manual\_Fraud\_Check** — cycle time, approval rate, resource cost — has no statistical power and extreme variance. If we treat C05's fast approve (≈ 25 min after the check) as representative, we may wrongly conclude that manual checks are quicker or more lenient than automated ones. Predictive models trained on this slice will either ignore the activity (under-fit) or over-fit to one data point. Generalising from n = 1 conflates coincidence with pattern; we cannot reliably distinguish the activity's true effect from case-specific noise.