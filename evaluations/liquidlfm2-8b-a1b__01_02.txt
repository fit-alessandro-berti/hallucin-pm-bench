4.0

### Evaluation Rationale
- **Decision Points (Major Errors – Severe Point Loss)**: The ground truth strictly identifies only three true decision branches (Underwriter Alignment Gate, Amount Threshold Decision, and Final Micro-loan Board Approval), focusing on conditional forks in the process with exact terminology and concise summaries. The LLM answer incorrectly frames the *entire process flow* (steps 1–9) as "Decision Points," including non-decision activities like application submission, KYC verification, CIA, Dual Underwriter Split, and NFC collection. This introduces extraneous steps, deviates from "summarise the decision points," and violates the instruction to use exact activity names without expanding into full procedural summaries. While it touches on the correct branches (e.g., alignment check in #5, threshold in #7, MBA in #8), the structure, scope, and phrasing (e.g., "triggers Final Micro-loan Board (MBA) review" vs. ground truth's "send to Final Micro-loan Board Approval") are imprecise and overinclusive. This core misinterpretation warrants a heavy deduction (equivalent to ~2/10 for this section alone).
  
- **Required Documents (Minor Errors – Moderate Point Loss)**: The list is nearly complete and uses exact terminology from the prompt (e.g., ML-APP-01, CIS, NFF). However, small phrasing inconsistencies include: "≤ 3 months old" (adds "old," not in ground truth's "≤ 3 months"); "single pay-stub or tax slip" (matches prompt but ground truth abbreviates to "pay-stub/tax slip," introducing slight verbosity). The ground truth uses numbered list and adds a clarifying note on exclusions (per prompt's avoidance of standard terminology), which the LLM omits. No major omissions, but strictness demands deduction for imperfect fidelity (~8/10 for this section).

- **Overall Structure and Adherence**: The LLM uses bold headings and bullets, which is functional but doesn't match the ground truth's "####" subheadings and numbered/italicized format. It adheres to "do not introduce standard loan terminology" but fails on "use exactly the activity names given" by rephrasing (e.g., "Dual Underwriter Assessment" vs. exact "Dual Underwriter Split"; "Collect at least 3 local reference checks" vs. "Neighbourhood Feedback Check (NFC)"). Combined, the dominant error in decision points (half the prompt's focus) drags the score down significantly, despite solid documents coverage. No criminal or policy violations noted.