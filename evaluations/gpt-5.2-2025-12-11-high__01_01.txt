7.0

### Evaluation Rationale (strict assessment vs. ground truth)
- **Strengths (partial credit)**: Correctly identifies all 7 required documents (exact match in completeness and qualifiers like "> €1 000" for *AuditTrail*). Captures core elements of eligibility check, pre-approval, and high-value branch accurately. No introduction of undefined activities/artefacts. Structure is clear and process-faithful.
- **Major deductions**:
  - **Decision points mismatch**: Lists **4 points** vs. ground truth's **3**. Introduces non-explicit "Payment readiness gate" (#4) as a decision/condition (with *BankTransferAuthorization*), which ground truth folds into #3 ("Final payment approval") without a separate gate. This adds an unlisted "decision," violating "summarise every **decision point**" by over-interpreting constraints (-2.0).
  - **Missing rejection outcomes**: Ground truth explicitly details failure branches (e.g., "*Not eligible* → rejected"; "*Rejected* → ends without payment") in table. LLM omits these, assuming success implicitly (-1.5).
  - **Separation of approvals**: Treats *Finance_Controller_PreApprove* as standalone decision (#2), while ground truth consolidates it with conditional *Senior_Auditor_Review* into one (#3) (-0.5).
- **Minor deductions**:
  - **Extra unrequested details**: Adds "Basis/Documents used" per point and interpretive phrasing (e.g., "disruption evidence"; "claim originates from") not in prompt or ground truth (-0.5).
  - **Format/structure divergence**: Narrative list + headers vs. ground truth's table + numbered doc list. No table for decisions; docs bulleted vs. numbered (-0.5).
- **Total**: High fidelity overall (80% alignment), but strict policy on differences (esp. count/content of decisions, omissions) yields 7.0. No perfect match.