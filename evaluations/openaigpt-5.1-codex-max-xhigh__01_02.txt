8.0

### Evaluation Rationale (strict assessment)
The LLM answer is highly accurate in identifying and describing the **3 core decision points** (Underwriter Alignment Gate, Amount Threshold Decision, Final Micro-loan Board Approval) using exact terminology, and lists **all 6 required documents** completely without additions or omissions. Logic for each decision matches the process flow precisely. However, under utmost strictness, the following differences from ground truth incur significant deductions (each small phrasing/context error treated as ~0.5-1.0 point loss due to instruction emphasis):

#### Decision Points (deduct ~1.5 points total):
- Missing key contextual placements: "branch after the Dual Underwriter Split" (-0.75) and "after Neighbourhood Feedback Check" (-0.75). These summarize flow position, essential for process summary.
- Phrasing variances: "≤ 2 points" vs "≤ 2" (-0.2); "escalate to the **Harmonisation Committee** for a tie-break decision, then continue" vs "escalate to Harmonisation Committee for tie-break" (extras: "the", "a", "decision", "then continue") (-0.3); "proceed to **Final Micro-loan Board Approval (MBA)**" vs "send to Final Micro-loan Board Approval" ("proceed"/bold/(MBA) vs "send") (-0.2); "Micro-loan Board votes *approve* or *reject*" vs "the board votes **Approve** or **Reject**" ("Micro-loan Board" vs "the board", lowercase/italics vs bold/caps) (-0.2).
- Structure: Bullets vs numbered (-0.1, minor format diff).

#### Required Documents (deduct ~0.5 points total):
- Phrasing: "≤ 3 months old" vs "≤ 3 months" (extra "old") (-0.2); "(single pay-stub or tax slip)" vs "(pay-stub/tax slip)" (extras "single"/"or" vs "/") (-0.2); "(CIS) template" vs "(CIS)" (extra "template") (-0.1).
- Structure: Bullets vs numbered (-0.1, minor); omits interpretive note (neutral, as not required).
- Extra header phrase "(using exact activity names)" and "**Required documents at submission time**" (minor, matches prompt intent but not GT).

**Total: Starts at 10.0, deducts 2.0 for cumulative small/context errors → 8.0**. No major factual errors, but strict criteria penalize all diffs heavily. Perfect match would require identical phrasing/structure/context.