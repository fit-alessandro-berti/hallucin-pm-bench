3.0

### Evaluation Rationale
The LLM answer attempts a BPMN 2.0 XML structure but contains critical structural and fidelity errors when strictly compared to the ground truth and prompt requirements. Even minor deviations result in significant deductions for exactness. Key issues:

- **Critical omission (major deduction: -4.0 points)**: No sequence flow from the "Provide Reset Instructions" task (id="reset") to "Confirm with Customer" (id="confirm"). This breaks the process flow for the "Password Reset" path, violating lines 3 and 7 of the description (reset is a resolution leading to confirmation). The BPMN is invalid/incomplete here, as the path dead-ends.

- **Invented elements (deduction: -1.5 points)**: Two separate "Resolve Issue" tasks (resolve1 and resolve2) instead of reusing a single one as in the ground truth. This subtly invents duplication not mentioned in the description (line 6 implies a single "Resolve Issue" after specialist work), contravening "Do not invent or add... activities."

- **Fidelity to description names (deduction: -0.5 points)**: "Classify Ticket" instead of implying "automatically classified" (ground truth uses "Auto-Classification"). Minor, but strict evaluation penalizes wording deviations.

- **Missing attributes and details (deduction: -0.5 points)**: No names on gateways (e.g., ground truth has "Password Reset?", "Resolved Internally?", "Customer Confirms?"), start/end events, or process (no id/name like "support_ticket"/"Support-Ticket"). No conditionExpressions (ground truth uses xsi:type="tFormalExpression" with "yes"/"no"; LLM relies on informal flow names like "Password Reset"/"Other", which is less precise).

- **Minor XML structure (deduction: -0.5 points)**: Lacks XML declaration, targetNamespace, and process attributes (e.g., isExecutable="false"). While the prompt specifies only a "<definitions> block", ground truth includes these for completeness; omission reduces parsability/exactness.

Positive aspects (partial credit): Correctly uses exclusive gateways for decisions (though prompt mentions "two", LLM/ground both use three for the loop), models the re-work loop accurately (gw3 â†’ diagnose), concise IDs/flows, under 40 lines, no invented timers/escalations/parallel paths. Overall functional skeleton is ~60% aligned, but omissions and inventions make it unreliable.